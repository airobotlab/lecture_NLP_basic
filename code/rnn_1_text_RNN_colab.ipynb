{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "KCUnpXlWTnwE"
      },
      "source": [
        "# 1) RNN 기초\n",
        "\n",
        "220603"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "3S1vwct7TnwH"
      },
      "source": [
        "## Naive Neural Networks 의 문제점\n",
        "\n",
        "```\n",
        "Yesterday, Harry Potter met Hermione Granger\n",
        "```\n",
        "\n",
        "- 사람 이름 = 1\n",
        "- 아니라면 = 0\n",
        "\n",
        "![](https://i.imgur.com/zPTrFRt.png)\n",
        "\n",
        "만약 아래 문장이라면 위의 구조로 가능할까?\n",
        "\n",
        "```\n",
        "First time Hermione meet Harry and Ron\n",
        "```\n",
        "\n",
        "#### 기계 번역 문제의 경우, 입력과 출력 시퀀스의 길이가 동일하지 않을수 있다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9NzT1M5oTnwI"
      },
      "source": [
        "## Recurrent Neural Networks (RNN)\n",
        "\n",
        "![](https://i.imgur.com/owxFJp3.png)\n",
        "\n",
        "### 장점\n",
        "\n",
        "- RNN Cell을 여러개 연결하여 유연한 구조를 만든다.\n",
        "- y^<2> 예측 시 x<2>만 사용하는 것이 아니라, 첫번째 단어로 연산한 정보의 일부(a<1>)를 사용하게 된다.\n",
        "\n",
        "### 기본적인 RNN 단점\n",
        "\n",
        "- 앞서 나온 단어들의 정보만을 사용한다.\n",
        "    - `He said, \"Teddy Roosevelt was a great President.\"`\n",
        "    - `He said, \"Teddy bears are on sale.\"`\n",
        "- Gradient vanishing\n",
        "    - `The cat, which already ate ............, was full`\n",
        "    - `The cats, which already ate ............, were full`\n",
        "    - 신경망이 깊어질수록 (문장이 길어질수록) 문장 초반부의 단어가 후반부 단어에 미치는 영향이 적어진다. (가까이 있는 입력 영향을 더 많이 받음)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "I245PkYbTnwJ"
      },
      "source": [
        "## RNN 발전형\n",
        "\n",
        "### RNN\n",
        "\n",
        "![](https://i.imgur.com/vcUIhTL.png)\n",
        "\n",
        "### Long Short-Term Memory (LSTM)\n",
        "\n",
        "![](https://i.imgur.com/VXeCc8x.png)\n",
        "\n",
        "LSTM은 메모리를 컨베이어 벨트같이 오래 전파하는 특성을 가진다.\n",
        "\n",
        "### Gated Recurrent Unit (GRU)\n",
        "\n",
        "![](https://i.imgur.com/fXeGJu6.png)\n",
        "\n",
        "- 일반적으로 GRU는 LSTM보다 학습 속도가 빠르다.\n",
        "- 여러 평가에서 GRU는 LSTM과 비슷한 성능을 보인다.\n",
        "- 데이터 양이 적을 때는 GRU를 사용하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "mjvJOpOuTnwJ"
      },
      "source": [
        "# 2) RNN 기반 텍스트 처리\n",
        "\n",
        "220603\n",
        "\n",
        "- [ref](https://github.com/graykode/nlp-tutorial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "hidden": true,
        "id": "SiM40ja4TnwK"
      },
      "outputs": [],
      "source": [
        "# code by Tae Hwan Jung @graykode\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def make_batch():\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "\n",
        "    for sen in sentences:\n",
        "        word = sen.split()  # space tokenizer\n",
        "        input = [word_dict[n] for n in word[:-1]]  # create (1~n-1) as input\n",
        "        target = word_dict[word[-1]]  # create (n) as target, We usually call this 'casual language model'\n",
        "\n",
        "        input_batch.append(np.eye(n_class)[input])\n",
        "        target_batch.append(target)\n",
        "\n",
        "    return input_batch, target_batch\n",
        "\n",
        "class TextRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=n_class, hidden_size=n_hidden)\n",
        "#         self.rnn = nn.GRU(input_size=n_class, hidden_size=n_hidden)        \n",
        "        \n",
        "        self.W = nn.Linear(n_hidden, n_class, bias=False)\n",
        "        self.b = nn.Parameter(torch.ones([n_class]))\n",
        "\n",
        "    def forward(self, hidden, X):\n",
        "        X = X.transpose(0, 1) # X : [n_step, batch_size, n_class]\n",
        "        outputs, hidden = self.rnn(X, hidden)\n",
        "        # outputs : [n_step, batch_size, num_directions(=1) * n_hidden]\n",
        "        # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "        outputs = outputs[-1] # [batch_size, num_directions(=1) * n_hidden]\n",
        "        model = self.W(outputs) + self.b # model : [batch_size, n_class]\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5F5BHUcTnwL",
        "outputId": "d7afcd0f-d2ee-4e39-b007-4a28a90a571f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n"
          ]
        }
      ],
      "source": [
        "n_step = 2 # number of cells(= number of Step)\n",
        "n_hidden = 5 # number of hidden units in one cell\n",
        "\n",
        "sentences = [\"i like dog\", \"i love coffee\", \"i hate milk\"]\n",
        "\n",
        "word_list = \" \".join(sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "n_class = len(word_dict)\n",
        "batch_size = len(sentences)\n",
        "\n",
        "model = TextRNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "input_batch, target_batch = make_batch()\n",
        "input_batch = torch.FloatTensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDnlPRJ9TnwL",
        "outputId": "1d342841-be23-40fb-c46f-5634747db13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000 cost = 0.193783\n",
            "Epoch: 2000 cost = 0.022608\n",
            "Epoch: 3000 cost = 0.007388\n",
            "Epoch: 4000 cost = 0.003477\n",
            "Epoch: 5000 cost = 0.001853\n",
            "[['i', 'like'], ['i', 'love'], ['i', 'hate']] -> ['dog', 'coffee', 'milk']\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for epoch in range(5000):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # hidden : [num_layers * num_directions, batch, hidden_size]\n",
        "    hidden = torch.zeros(1, batch_size, n_hidden)\n",
        "    # input_batch : [batch_size, n_step, n_class]\n",
        "    output = model(hidden, input_batch)\n",
        "\n",
        "    # output : [batch_size, n_class], target_batch : [batch_size] (LongTensor, not one-hot)\n",
        "    loss = criterion(output, target_batch)\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "input = [sen.split()[:2] for sen in sentences]\n",
        "\n",
        "# Predict\n",
        "hidden = torch.zeros(1, batch_size, n_hidden)\n",
        "predict = model(hidden, input_batch).data.max(1, keepdim=True)[1]\n",
        "print([sen.split()[:2] for sen in sentences], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "hidden": true,
        "id": "6qhAjIDVTnwM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "hidden": true,
        "id": "aY4ixXh2TnwN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "hidden": true,
        "id": "al5qJjnvTnwN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "rnn_1_text_RNN_colab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}