{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pV286PDi-_u"
      },
      "source": [
        "# 문서 벡터화 알고리즘 실습\n",
        "\n",
        "220527\n",
        "\n",
        "- 1) BOW\n",
        "- 2) DTW\n",
        "- 3) TF-IDF\n",
        "- 4) 문서 검색 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKJFFDbDi-_x",
        "outputId": "e54869a2-aed3-40ea-a003-f89756b4eb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 97.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# install\n",
        "!python -m pip install konlpy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "tECk1yKL-07X"
      },
      "source": [
        "## 1) BoW (Bag of Words) 기반 문서 벡터화\n",
        "\n",
        "- [ref](https://wikidocs.net/22650)\n",
        "\n",
        "Bag of Words (단어들의 가방이)\n",
        "- 단어들의 순서는 전혀 고려 없이 단어들의 출현 빈도(frequency)만으로 텍스트를 수치화\n",
        "- 모든 텍스트 문서를 가방에 넣고 섞은 후 단어를 섞는다\n",
        "\n",
        "BoW를 만드는 과정을 이렇게 두 가지 과정으로 생각해보겠습니다.\n",
        "\n",
        "- 1) 각 단어에 고유한 정수 인덱스를 부여\n",
        "- 2) 각 단어의 출현 빈도수 저장\n",
        "- 불용어를 제거하면 더 좋은 성능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "id": "cY-DFrWti-_z"
      },
      "outputs": [],
      "source": [
        "## bow function\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "def build_bag_of_words(document):\n",
        "    # 온점 제거 및 형태소 분석\n",
        "    document = document.replace('.', '')\n",
        "    tokenized_document = okt.morphs(document)\n",
        "\n",
        "    word_to_index = {}\n",
        "    bow = []\n",
        "    for word in tokenized_document:\n",
        "        if word not in word_to_index.keys():\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "            # BoW에 전부 기본값 1을 넣는다.\n",
        "            bow.insert(len(word_to_index) - 1, 1)\n",
        "        else:\n",
        "            # 재등장하는 단어의 인덱스\n",
        "            index = word_to_index.get(word)\n",
        "            # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
        "            bow[index] = bow[index] + 1\n",
        "\n",
        "    return word_to_index, bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaR6xMnqi-_0",
        "outputId": "af94a14c-d596-4c72-ac92-0702ea3b04dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "## 예시 1)\n",
        "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "vocab, bow = build_bag_of_words(doc1)\n",
        "\n",
        "print('input: %s'%(doc1))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLu4G5yYi-_1",
        "outputId": "22d2ff89-8bd0-465e-dfa7-1efef39bd772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "## 예시 2)\n",
        "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
        "\n",
        "vocab, bow = build_bag_of_words(doc2)\n",
        "\n",
        "print('input: %s'%(doc2))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkkkJ00xi-_1",
        "outputId": "9dbf31eb-bdee-4e42-fe2b-7064d045f080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "## 예시 3) 문서1과 문서2를 합쳐서 구할 수 있음\n",
        "doc3 = doc1 + ' ' + doc2\n",
        "vocab, bow = build_bag_of_words(doc3)\n",
        "\n",
        "print('input: %s'%(doc3))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VINGWzrNi-_2",
        "outputId": "acd11163-423b-4404-c894-bf9f44fda2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: [('기준', 0), ('느끼는', 1), ('느낀다', 2), ('다르다', 3), ('물가상승률', 4), ('발표', 5), ('상품', 6), ('소비', 7), ('소비자', 8), ('으로', 9), ('정부', 10), ('주로', 11), ('하는', 12)]\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [[1 1 1 1 3 1 1 1 2 1 1 1 2]]\n"
          ]
        }
      ],
      "source": [
        "## 3. CountVectorizer 클래스로 BoW 만들기\n",
        "# 단어의 빈도를 Count하여 Vector로 만드는 사이킷런의 CountVectorizer를 이용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# corpus = ['you know I want your love. because I love you.']\n",
        "corpus = [' '.join(okt.morphs(doc3))]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "\n",
        "bow = vector.fit_transform(corpus).toarray()\n",
        "vocab = sorted(vector.vocabulary_.items())\n",
        "\n",
        "print('input: %s'%(doc3))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "pXsgP6ZPi-_3"
      },
      "source": [
        "## 2) 문서 단어 행렬(Document-Term Matrix, DTM) 기반 문서 벡터화\n",
        "\n",
        "- [ref](https://wikidocs.net/31698)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "hidden": true,
        "id": "dpqunYJ7i-_4"
      },
      "outputs": [],
      "source": [
        "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
        "doc3 = doc1 + ' ' + doc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URtC19hRi-_4",
        "outputId": "85be5f05-180e-4d5e-d4c5-b879b2f1c79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: ['정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.', '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.', '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.']\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: [('기준으로', 0), ('느끼는', 1), ('느낀다', 2), ('다르다', 3), ('물가상승률과', 4), ('물가상승률은', 5), ('물가상승률을', 6), ('발표하는', 7), ('상품을', 8), ('소비자가', 9), ('소비자는', 10), ('소비하는', 11), ('정부가', 12), ('주로', 13)]\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector:\n",
            " [[0 1 0 1 1 1 0 1 0 1 0 0 1 0]\n",
            " [1 0 1 0 0 0 1 0 1 0 1 1 0 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "## DTW\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [doc1, doc2, doc3]\n",
        "vector = CountVectorizer()\n",
        "\n",
        "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "DTW = vector.fit_transform(corpus).toarray()\n",
        "# 각 단어와 맵핑된 인덱스 출력\n",
        "vocab = sorted(vector.vocabulary_.items())\n",
        "\n",
        "print('input: %s'%(corpus))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:\\n', DTW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "hidden": true,
        "id": "qydHVtnTi-_5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "pyPrDUuyi-_5"
      },
      "source": [
        "## 3) TF-IDF 기반 문서 벡터화\n",
        "\n",
        "- [ref](https://wikidocs.net/31698)\n",
        "\n",
        "\n",
        "- (1) TF(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "    - TF는 각 문서에서 각 단어의 등장 빈도\n",
        "    \n",
        "- (2) DF(t) : 특정 단어 t가 등장한 문서의 수\n",
        "\n",
        "- (3) IDF(d, t) : df(t)에 반비례값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmhQq4_fi-_5",
        "outputId": "2ad5e8e7-e471-40b0-a15a-10e811cef151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: ['정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.', '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.', '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.']\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: [('기준으로', 0), ('느끼는', 1), ('느낀다', 2), ('다르다', 3), ('물가상승률과', 4), ('물가상승률은', 5), ('물가상승률을', 6), ('발표하는', 7), ('상품을', 8), ('소비자가', 9), ('소비자는', 10), ('소비하는', 11), ('정부가', 12), ('주로', 13)]\n",
            "\n",
            "2) 각 단어의 TF-IDF\n",
            "   =>bag of words vector:\n",
            " [[0.         0.37796447 0.         0.37796447 0.37796447 0.37796447\n",
            "  0.         0.37796447 0.         0.37796447 0.         0.\n",
            "  0.37796447 0.        ]\n",
            " [0.37796447 0.         0.37796447 0.         0.         0.\n",
            "  0.37796447 0.         0.37796447 0.         0.37796447 0.37796447\n",
            "  0.         0.37796447]\n",
            " [0.26726124 0.26726124 0.26726124 0.26726124 0.26726124 0.26726124\n",
            "  0.26726124 0.26726124 0.26726124 0.26726124 0.26726124 0.26726124\n",
            "  0.26726124 0.26726124]]\n"
          ]
        }
      ],
      "source": [
        "# tf-idf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# corpus = [\n",
        "#     'you know I want your love',\n",
        "#     'I like you',\n",
        "#     'what should I do ',    \n",
        "# ]\n",
        "corpus = [doc1, doc2, doc3]\n",
        "\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "\n",
        "TFIDF = tfidfv.transform(corpus).toarray()\n",
        "vocab = sorted(tfidfv.vocabulary_.items())\n",
        "\n",
        "print('input: %s'%(corpus))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 TF-IDF\\n   =>bag of words vector:\\n', TFIDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQgZ8YGki-_6"
      },
      "source": [
        "# 4) 벡터 유사도\n",
        "\n",
        "- [url](https://wikidocs.net/24603)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXzcl2APi-_6",
        "outputId": "27cf3afd-d6a1-41c8-868f-d7d0be02df1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서1과 문서Q의 거리 : 2.23606797749979\n",
            "문서2과 문서Q의 거리 : 3.1622776601683795\n",
            "문서3과 문서Q의 거리 : 2.449489742783178\n"
          ]
        }
      ],
      "source": [
        "# 4.1) 유클리드 거리(Euclidean distance)\n",
        "import numpy as np\n",
        "\n",
        "def dist(x,y):   \n",
        "    return np.sqrt(np.sum((x-y)**2))\n",
        "\n",
        "doc1 = np.array((2,3,0,1))\n",
        "doc2 = np.array((1,2,3,1))\n",
        "doc3 = np.array((2,1,2,2))\n",
        "docQ = np.array((1,1,0,1))\n",
        "\n",
        "print('문서1과 문서Q의 거리 :',dist(doc1,docQ))\n",
        "print('문서2과 문서Q의 거리 :',dist(doc2,docQ))\n",
        "print('문서3과 문서Q의 거리 :',dist(doc3,docQ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXhFg5Qli-_6",
        "outputId": "782ef3c4-9463-4b02-ac5a-f3b9bba245fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서1 : ['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
            "문서2 : ['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n",
            "문서1과 문서2의 합집합 : {'likey', 'watch', 'holder', 'coupon', 'passport', 'love', 'like', 'apple', 'everyone', 'banana', 'card', 'you'}\n",
            "문서1과 문서2의 교집합 : {'banana', 'apple'}\n",
            "자카드 유사도 : 0.16666666666666666\n"
          ]
        }
      ],
      "source": [
        "# 4.2) 자카드 유사도(Jaccard similarity)\n",
        "doc1 = \"apple banana everyone like likey watch card holder\"\n",
        "doc2 = \"apple banana coupon passport love you\"\n",
        "\n",
        "# 토큰화\n",
        "tokenized_doc1 = doc1.split()\n",
        "tokenized_doc2 = doc2.split()\n",
        "\n",
        "print('문서1 :',tokenized_doc1)\n",
        "print('문서2 :',tokenized_doc2)\n",
        "\n",
        "union = set(tokenized_doc1).union(set(tokenized_doc2))\n",
        "print('문서1과 문서2의 합집합 :',union)\n",
        "\n",
        "intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))\n",
        "print('문서1과 문서2의 교집합 :',intersection)\n",
        "\n",
        "print('자카드 유사도 :',len(intersection)/len(union))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH93gqFsi-_7",
        "outputId": "e3373418-9ceb-4f7a-f00a-965ce2e4fc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서 1과 문서2의 유사도 : 0.6666666666666667\n",
            "문서 1과 문서3의 유사도 : 0.6666666666666667\n",
            "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "## 4.3) 코사인 유사도(Cosine Similarity)\n",
        "# 벡터의 방향(패턴)에 초점을 두므로 코사인 유사도는 문서의 길이가 다른 상황에서 비교적 공정한 비교\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(A, B):\n",
        "    return dot(A, B)/(norm(A)*norm(B))\n",
        "\n",
        "doc1 = np.array([0, 1, 1, 1])\n",
        "doc2 = np.array([1, 0, 1, 1])\n",
        "doc3 = np.array([2, 0, 2, 2])\n",
        "\n",
        "print('문서 1과 문서2의 유사도 :', cos_sim(doc1, doc2))\n",
        "print('문서 1과 문서3의 유사도 :', cos_sim(doc1, doc3))\n",
        "print('문서 2와 문서3의 유사도 :', cos_sim(doc2, doc3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ToIk_p0qi-_7"
      },
      "source": [
        "## 5) BM25, 유사도 기반 문서 검색\n",
        "\n",
        "- [url](https://github.com/dorianbrown/rank_bm25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "code_folding": [
          0,
          22,
          23,
          37,
          60,
          74,
          84,
          85,
          91,
          113,
          129,
          143
        ],
        "hidden": true,
        "id": "yI4weB7Zi-_7"
      },
      "outputs": [],
      "source": [
        "## load, BM25 구현코드, https://github.com/dorianbrown/rank_bm25\n",
        "# [비슷한 문장들의 idx], [비슷한 문장듯] = bm25_model.get_top_n(tokenized_query, question_list, n=5)\n",
        "'''\n",
        "- 사용법\n",
        "corpus = [\n",
        "    \"Hello there good man!\",\n",
        "    \"It is quite windy in London\",\n",
        "    \"How is the weather today?\"\n",
        "]\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "query = \"windy London\"\n",
        "tokenized_query = query.split(\" \")\n",
        "doc_scores = bm25.get_scores(tokenized_query)  # array([0.        , 0.93729472, 0.        ])\n",
        "bm25.get_top_n(tokenized_query, corpus, n=1)  # 비슷한 문장들의 idx], [비슷한 문장듯]\n",
        "'''\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import pandas as pd\n",
        "\n",
        "class BM25:\n",
        "    def __init__(self, corpus, tokenizer=None):\n",
        "        self.corpus_size = len(corpus)\n",
        "        self.avgdl = 0\n",
        "        self.doc_freqs = []\n",
        "        self.idf = {}\n",
        "        self.doc_len = []\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if tokenizer:\n",
        "            corpus = self._tokenize_corpus(corpus)\n",
        "\n",
        "        nd = self._initialize(corpus)\n",
        "        self._calc_idf(nd)\n",
        "\n",
        "    def _initialize(self, corpus):\n",
        "        nd = {}  # word -> number of documents with word\n",
        "        num_doc = 0\n",
        "        for document in corpus:\n",
        "            self.doc_len.append(len(document))\n",
        "            num_doc += len(document)\n",
        "\n",
        "            frequencies = {}\n",
        "            for word in document:\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 0\n",
        "                frequencies[word] += 1\n",
        "            self.doc_freqs.append(frequencies)\n",
        "\n",
        "            for word, freq in frequencies.items():\n",
        "                try:\n",
        "                    nd[word]+=1\n",
        "                except KeyError:\n",
        "                    nd[word] = 1\n",
        "\n",
        "        self.avgdl = num_doc / self.corpus_size\n",
        "        return nd\n",
        "\n",
        "    def _tokenize_corpus(self, corpus):\n",
        "        pool = Pool(cpu_count())\n",
        "        tokenized_corpus = pool.map(self.tokenizer, corpus)\n",
        "        return tokenized_corpus\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_top_n(self, query, documents, n=5):\n",
        "\n",
        "        # index도 출력되게 수정\n",
        "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "\n",
        "        scores = self.get_scores(query)\n",
        "        top_n = np.argsort(scores)[::-1][:n]\n",
        "        return top_n.tolist(), [documents[i] for i in top_n]  # wygo 수정, idx도 출력되도록\n",
        "\n",
        "\n",
        "class BM25Okapi(BM25):\n",
        "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.epsilon = epsilon\n",
        "        super().__init__(corpus, tokenizer)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        \"\"\"\n",
        "        Calculates frequencies of terms in documents and in corpus.\n",
        "        This algorithm sets a floor on the idf values to eps * average_idf\n",
        "        \"\"\"\n",
        "        # collect idf sum to calculate an average idf for epsilon value\n",
        "        idf_sum = 0\n",
        "        # collect words with negative idf to set them a special epsilon value.\n",
        "        # idf can be negative if word is contained in more than half of documents\n",
        "        negative_idfs = []\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
        "            self.idf[word] = idf\n",
        "            idf_sum += idf\n",
        "            if idf < 0:\n",
        "                negative_idfs.append(word)\n",
        "        self.average_idf = idf_sum / len(self.idf)\n",
        "\n",
        "        eps = self.epsilon * self.average_idf\n",
        "        for word in negative_idfs:\n",
        "            self.idf[word] = eps\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        \"\"\"\n",
        "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
        "        this algorithm also adds a floor to the idf value of epsilon.\n",
        "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
        "        :param query:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
        "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "        return score\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        \"\"\"\n",
        "        Calculate bm25 scores between query and subset of all docs\n",
        "        \"\"\"\n",
        "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
        "        score = np.zeros(len(doc_ids))\n",
        "        doc_len = np.array(self.doc_len)[doc_ids]\n",
        "        for q in query:\n",
        "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
        "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
        "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "        return score.tolist()\n",
        "\n",
        "    \n",
        "def IR_BM25(query, bm25_model, tokenizer='space', n=5):\n",
        "    '''\n",
        "    input\n",
        "        query: '. 윗글에서 확인할 수 있는 ㉠의 방법이 아닌 것은?'\n",
        "        bm25_model: BM25Okapi(tokenized_corpus)\n",
        "        tokenizer: mecab 형태소 분석기\n",
        "    '''\n",
        "    # 쿼리 프리프로세싱\n",
        "#     query = '27. ㉠에 대한 이해로 가장 적절한 것은?'\n",
        "#     query = '1. 윗글에서 확인할 수 있는 ㉠의 방법이 아닌 것은?'\n",
        "\n",
        "    if tokenizer=='space':\n",
        "        tokenized_query = query.split()\n",
        "    else:\n",
        "        tokenized_query = tokenizer(query)\n",
        "    \n",
        "    doc_representation = bm25_model.get_scores(tokenized_query)  # array([0.        , 0.93729472, 0.        ])\n",
        "\n",
        "    # 유사문장 가져오기\n",
        "    similar_idx, similar_sentences = bm25_model.get_top_n(tokenized_query, question_list, n)\n",
        "\n",
        "    print('- query : %s' % (query))\n",
        "    print('- similar\\n%s' % ('\\n'.join(similar_sentences)))\n",
        "    \n",
        "    return similar_idx, similar_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5oqwGkOi-_9",
        "outputId": "5023d326-c3df-453c-ec10-e15587913e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45. <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지않은 것은? [3점]\n",
            "번호 제거 ==>>  <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지않은 것은? [3점]\n"
          ]
        }
      ],
      "source": [
        "# 0) DB에 있는 문제들을 가져와서 앞의 번호를 제거한 후 list를 만든다\n",
        "question_list = ['8. (나)에 활용된 글쓰기 전략으로 적절하지 않은 것은?',\n",
        "                 '9. <보기>는 (나)의 ‘학생’이 ‘초고’를 보완하기 위해 추가로 수집한 자료이다. 자료 활용 방안으로 적절하지 않은 것은?',\n",
        "                 '10. 다음은 (나)의 ‘학생’이 ‘초고’를 고쳐 쓰는 과정에서 수행한 학습 활동이다. [A]에 들어갈 내용으로 가장 적절한 것은?',\n",
        "                 '11. ㉠과 ㉡을 모두 충족하는 단어만을 <보기>에서 있는 대로 고른 것은?',\n",
        "                 '12. 윗글과 <보기>를 바탕으로 추론한 내용으로 적절하지 않은 것은?',\n",
        "                 '13. ⓐ～ⓔ는 잘못된 표기를 바르게 고친 것이다. 고치는 과정에서 해당 단어에 적용된 용언 활용의 예로 적절하지 않은 것은?',\n",
        "                 '14. <학습 활동>을 수행한 결과로 적절하지 않은 것은? [3점]',\n",
        "                 '15. <보기>의 ㉠과 ㉡에 들어갈 말로 적절한 것은?',\n",
        "                 '16. (가), (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '17. (가)의 ‘박제가’와 ‘이덕무’에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '18. 평등견 에 대한 이해로 가장 적절한 것은?',\n",
        "                 '19. 문맥을 고려할 때 ㉠의 의미를 파악한 내용으로 가장 적절한 것은?',\n",
        "                 '20. <보기>는 (가)에 제시된 \\U000f0854북학의\\U000f0855의 일부이다. [A]와 (나)를 참고하여 <보기>에 대해 비판적 읽기를 수행한 학생의 반응으로 적절하지 않은 것은? [3점]',\n",
        "                 '21. 문맥상 ⓐ～ⓔ와 바꿔 쓰기에 가장 적절한 것은?',\n",
        "                 '22. [A]와 [B]의 서술상 특징에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '23. 윗글에 대한 이해로 가장 적절한 것은?',\n",
        "                 '24. ⓐ, ⓑ에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '25. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '26. 윗글에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '27. ㉠에 대한 이해로 가장 적절한 것은?',\n",
        "                 '28. 다음은 [A]에 제시된 예를 활용하여, 예약의 유형에 따라 예약상 권리자가 요구할 수 있는 급부에 대해 정리한 것이다. ㄱ～ㄷ에 들어갈 내용을 올바르게 짝지은 것은?',\n",
        "                 '29. 윗글을 참고할 때, <보기>의 ㉮에 대한 이해로 적절하지 않은 것은? [3점]',\n",
        "                 '30. 문맥상 ⓐ～ⓔ의 단어와 가장 가까운 의미로 쓰인 것은?',\n",
        "                 '31. 윗글의 서술상 특징으로 가장 적절한 것은?',\n",
        "                 '32. 윗글의 내용에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '33. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '34. 윗글에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '35. 모델링 에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '36. ㉠에 대한 추론으로 적절한 것은?',\n",
        "                 '37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]',\n",
        "                 '38. (가)와 (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '39. <보기>를 바탕으로 (가)를 감상한 내용으로 적절하지 않은 것은?',\n",
        "                 '40. <보기>를 바탕으로 (나), (다)를 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '41. (가)와 (다)를 비교하여 이해한 내용으로 가장 적절한 것은?',\n",
        "                 '42. (다)에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '43. (가)에 대한 이해로 가장 적절한 것은?',\n",
        "                 '44. ㉠～㉤의 의미를 고려하여 (나)를 감상한 내용으로 적절하지 않은 것은?',\n",
        "                 '45. <보기>를 참고하여 (가)와 (나)를 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '1. 윗글에서 확인할 수 있는 ㉠의 방법이 아닌 것은?',\n",
        "                 '2. 윗글을 바탕으로 <보기>를 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '3. 다음은 윗글을 읽은 학생의 반응이다. 이에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '4. 다음은 (가)와 (나)를 읽은 학생이 작성한 학습 활동지의 일부 이다. ㄱ～ㅁ에 들어갈 내용으로 적절하지 않은 것은?',\n",
        "                 '5. 윗글에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '6. [A]에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '7. ㉠, ㉡에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '8. 는 윗글의 주제와 관련한 동서양 학자들의 견해이다. 윗글을 읽은 학생이 에 대해 보인 반응으로 적절하지 않은 것은? [3점]',\n",
        "                 '9. ⓐ와 문맥상 의미가 가장 가까운 것은?',\n",
        "                 '10. 윗글에서 베카리아의 관점으로 보기 어려운 것은?',\n",
        "                 '11. ㉠에 대한 설명으로 적절하지 않은 것은?',\n",
        "                 '12. 윗글을 바탕으로 베카리아의 입장을 추론한 내용으로 가장 적절한 것은? [3점]',\n",
        "                 '13. 문맥상 ⓐ～ⓔ와 바꿔 쓰기에 적절하지 않은 것은?',\n",
        "                 '14. 윗글에서 알 수 있는 내용으로 적절하지 않은 것은?',\n",
        "                 '15. ㉠과 ㉡에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '16. 어느 바이러스 감염증의 진단 검사에 PCR를 이용하려고 한다. 윗글을 읽고 이해한 반응으로 가장 적절한 것은?',\n",
        "                 '17. [A]를 바탕으로 의 실험 상황을 가정하고 와 같이 예상 결과를 추론하였다. ㉮～㉰에 들어갈 말로 적절한 것은?',\n",
        "                 '18. [A]의 서술상 특징으로 가장 적절한 것은?',\n",
        "                 '19. 서사의 흐름을 고려하여 ㉠～㉤에 대해 이해한 내용으로 적절 하지 않은 것은?',\n",
        "                 '20. ⓐ，ⓑ에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '21. <보기>의 관점에서 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '22. (가)와 (나)의 공통점으로 가장 적절한 것은?',\n",
        "                 '23. (나)에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '24. 문맥을 고려하여 ㉠～㉤에 대해 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '25. (나)와 (다)를 비교하여 이해한 내용으로 가장 적절한 것은?',\n",
        "                 '26. [A]와 [B]에 대한 이해로 가장 적절한 것은?',\n",
        "                 '27. 를 바탕으로 (가)～(다)를 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '28. 윗글의 내용에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '29. ⓐ와 ⓑ에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '30. [A]의 ‘달’에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '31. <보기>를 참고하여 ㉠～㉤을 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '32. (가)와 (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '33. (가), (나)의 시어에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '34. <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '35. 위 강연자의 말하기 방식으로 가장 적절한 것은?',\n",
        "                 '36. 다음은 동아리 부장이 강연자에게 보낸 전자 우편이다. 이를 바탕으로 세운 강연자의 계획 중 강연에 반영되지 않은 것은?',\n",
        "                 '37. 다음은 학생이 강연을 들으면서 작성한 메모이다. 이를 바탕 으로 학생의 듣기 과정을 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '38. 대화의 흐름을 고려할 때, ㉠～㉤에 대한 설명으로 적절하지 않은 것은?',\n",
        "                 '39. [A]의 학생 1의 발화에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '40. (가)의 대화 내용이 (나), (다)에 각각 반영된 양상으로 적절 하지 않은 것은?',\n",
        "                 '41. 작문 맥락을 고려할 때 (나), (다)에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '42. <보기>를 점검 기준으로 할 때 ⓐ, ⓑ를 고쳐 쓰기 위한 방안으로 가장 적절한 것은?',\n",
        "                 '43. 다음은 초고를 작성하기 전에 학생이 떠올린 생각이다. ⓐ～ⓔ 중 학생의 초고에 반영되지 않은 것은?',\n",
        "                 '44. 다음은 초고를 읽은 교지 편집부 담당 선생님의 조언이다. 이를 반영하여 [A]를 작성한 내용으로 가장 적절한 것은?',\n",
        "                 '45. <보기>는 학생이 초고를 보완하기 위해 추가로 수집한 자료 이다. 자료의 활용 방안으로 적절하지 않은 것은? [3점]',\n",
        "                 '35. ㉠과 ㉡을 모두 만족하는 용언의 짝으로 적절한 것은?',\n",
        "                 '36. [A]를 바탕으로 의 ⓐ～ⓔ의 밑줄 친 부분을 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '37. <학습 활동>을 수행한 결과로 적절한 것은? [3점]',\n",
        "                 '38. <보기>의 ㉠～㉦에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '39. <보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?',\n",
        "                 '40. 위 화면을 통해 매체의 특성을 이해한 학생의 반응으로 가장 적절한 것은?',\n",
        "                 '41. <보기>를 참고할 때, [A]에 대한 반응으로 적절하지 않은 것은? [3점]',\n",
        "                 '42. 다음은 학생이 과제 수행을 위해 작성한 메모이다. 메모를 반영한 영상 제작 계획으로 적절하지 않은 것은?',\n",
        "                 '43. (가), (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '44. (가)의 언어적 특성을 고려할 때, ㉠～㉤에 대한 설명으로 적절하지 않은 것은?',\n",
        "                 '1. 위 발표에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '2. 다음은 발표를 하기 위해 작성한 메모와 발표 계획이다. 발표 내용에 반영되지 않은 것은?',\n",
        "                 '3. <보기>는 위 발표를 들은 학생들의 반응이다. 발표의 내용을 고려하여 학생의 반응을 이해한 내용으로 가장 적절한 것은?',\n",
        "                 '4. (가)에 나타난 의사소통 방식으로 적절하지 않은 것은?',\n",
        "                 '5. <보기1>은 ‘지도사’가 받은 전자 우편의 내용이고, 는 ‘지도사’가 인터뷰를 위해 준비한 자료이다. ㉠～㉢의 활용 계획 중 (가)에 드러나지 않은 것은? [3점]',\n",
        "                 '6. (가)와 (나)를 고려할 때, 학생이 글을 쓰기 위해 떠올렸을 생각으로 적절하지 않은 것은?',\n",
        "                 '7. 다음을 고려할 때, [A]에 들어갈 내용으로 가장 적절한 것은?',\n",
        "                 '8. ㉠～㉤ 중 (나)에 반영되지 않은 것은?',\n",
        "                 '9. <보기>는 [A]의 초고이다. 를 [A]로 고쳐 쓸 때 반영한 친구의 조언으로 가장 적절한 것은?',\n",
        "                 '10. 다음은 (나)를 읽은 학생이 이를 참고하여 작성한 글의 일부 이다. (나)의 정보를 활용한 방식으로 가장 적절한 것은? [3점]',\n",
        "                 '11. <보기>의 ㉮에 들어갈 말로 적절한 것은?',\n",
        "                 '12. 윗글을 읽고 추론한 내용으로 적절하지 않은 것은?',\n",
        "                 '13. <보기>의 [자료]에서 ㉠에 해당하는 단어만을 있는 대로 고른 것은? [3점]',\n",
        "                 '14. <학습 활동>을 수행한 결과로 적절한 것은?',\n",
        "                 '15. <보기>에 대한 이해로 적절한 것은?',\n",
        "                 '16. [A]의 서술상 특징에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '17. [B]에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '18. 요구 조건 을 중심으로 윗글을 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '19. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '20. (가)와 (나)의 공통적인 내용 전개 방식으로 가장 적절한 것은?',\n",
        "                 '21. (가)의 형식론 에 대한 이해로 가장 적절한 것은?',\n",
        "                 '22. (가)에 등장하는 이론가와 예술가들이 상대의 견해나 작품을 평가할 수 있는 말로 적절하지 않은 것은?',\n",
        "                 '23. 다음은 비평문을 쓰기 위해 미술 전람회에 다녀온 학생이 (가)와 (나)를 읽은 후 작성한 메모의 일부이다. 메모의 내용이 적절하지 않은 것은? [3점]',\n",
        "                 '24. 피카소의 게르니카 에 대해 <보기>의 A는 ㉠의 관점, B는 ㉡의 관점에서 비평한 내용이다. (나)를 바탕으로 A, B를 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '25. 문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?',\n",
        "                 '26. 윗글의 내용과 일치하는 것은?',\n",
        "                 '27. ㉠의 이유로 가장 적절한 것은?',\n",
        "                 '28. 행정규칙 에 관한 설명 중 적절하지 않은 것은?',\n",
        "                 '29. 윗글을 바탕으로 <보기>의 ㉮～㉰에 대해 이해한 내용으로 가장 적절한 것은? [3점]',\n",
        "                 '30. 문맥상 ⓐ～ⓔ와 바꿔 쓰기에 가장 적절한 것은?',\n",
        "                 '31. ㉠에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '32. [A]에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '33. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '34. 윗글에서 답을 찾을 수 있는 질문에 해당하지 않는 것은?',\n",
        "                 '35. 윗글을 읽고 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '36. ㉠～㉢에 대한 설명으로 적절한 것은?',\n",
        "                 '37. <보기>는 윗글을 읽은 학생이 ‘가상의 실험 결과’를 보고 추론한 내용이다. [가]에 들어갈 말로 적절하지 않은 것은? [3점]',\n",
        "                 '38. (나)의 시상 전개에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '39. (가)를 참고하여 (나)를 감상한 내용으로 적절하지 않은 것은?',\n",
        "                 '40. (다)를 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '41. ㉠, ㉡에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '42. ⓐ를 바탕으로 (나), (다)를 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '43. (가)에 대한 이해로 가장 적절한 것은?',\n",
        "                 '44. ㉠～㉤에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '45. <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지않은 것은? [3점]']\n",
        "\n",
        "print(question_list[-1])\n",
        "# 문제에서 번호 제거\n",
        "# '. ' 기준으로 문제 제거, ex) '37. '를 없앰\n",
        "question_list = [' '.join(tmp.split('. ')[1:]) for tmp in question_list]\n",
        "\n",
        "print('번호 제거 ==>> ', question_list[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8lQsRnLi-_9",
        "outputId": "7e751dde-2cae-4a63-c66d-09c8560d0720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okt check : ['37', '.', '다음', '은', '3', 'D', '애니메이션', '제작', '을', '위', '한', '계획', '의', '일부', '이다', '.', '윗', '글', '을', '바탕', '으로', '할', '때', '적절하지', '않은', '것', '은', '?', '[', '3', '점', ']']\n"
          ]
        }
      ],
      "source": [
        "## 1) DB에 있는 문장들을 형태소 단위로 쪼개준다\n",
        "tokenizer = 'okt'  # konlpy, no need java, only python\n",
        "\n",
        "# load question list\n",
        "sentence = '37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]'\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt().morphs\n",
        "print('okt check :', tokenizer(sentence))\n",
        "tokenized_corpus = [tokenizer(sentence) for sentence in question_list]  # 형태소 기반 분절\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V2335m0i-_-",
        "outputId": "8055fa28-2955-4e5d-a315-d7ebe39c1452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ['윗', '글', '과', '<', '보기', '>', '를', '바탕', '으로', '추론', '한', '내용', '으로', '적절하지', '않은', '것', '은', '?']\n"
          ]
        }
      ],
      "source": [
        "## 2) 모든 문제들의 BM25 벡터를 미리 구한다\n",
        "# BM25 계산\n",
        "bm25_model = BM25Okapi(tokenized_corpus)\n",
        "print('\\n',tokenized_corpus[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MagjDAzRi-_-",
        "outputId": "9477b53a-459d-4ad4-eb8b-f725fab45c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]\n",
            "- similar\n",
            "다음은 3D 애니메이션 제작을 위한 계획의 일부이다 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]\n",
            "다음은 학생이 과제 수행을 위해 작성한 메모이다 메모를 반영한 영상 제작 계획으로 적절하지 않은 것은?\n",
            "윗글을 바탕으로 <보기>를 이해한 내용으로 적절하지 않은 것은? [3점]\n",
            "다음은 학생이 강연을 들으면서 작성한 메모이다 이를 바탕 으로 학생의 듣기 과정을 이해한 내용으로 적절하지 않은 것은? [3점]\n",
            "윗글을 바탕으로 베카리아의 입장을 추론한 내용으로 가장 적절한 것은? [3점]\n"
          ]
        }
      ],
      "source": [
        "query = '37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer, n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95I3129Wi-_-",
        "outputId": "ccd8113b-a689-41f4-c355-d17d7649a1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 39. <보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?\n",
            "- similar\n",
            "<보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?\n",
            "ⓐ～ⓔ는 잘못된 표기를 바르게 고친 것이다 고치는 과정에서 해당 단어에 적용된 용언 활용의 예로 적절하지 않은 것은?\n",
            "<보기>의 [자료]에서 ㉠에 해당하는 단어만을 있는 대로 고른 것은? [3점]\n",
            "<보기>를 점검 기준으로 할 때 ⓐ, ⓑ를 고쳐 쓰기 위한 방안으로 가장 적절한 것은?\n",
            "<보기>를 참고할 때, [A]에 대한 반응으로 적절하지 않은 것은? [3점]\n"
          ]
        }
      ],
      "source": [
        "query = '39. <보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muM-jCbmi-_-",
        "outputId": "f2067066-79b2-4552-84c3-e4a92773cf60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 27. ㉠에 대한 이해로 가장 적절한 것은?\n",
            "- similar\n",
            "㉠에 대한 이해로 가장 적절한 것은?\n",
            "㉠에 대한 이해로 적절하지 않은 것은?\n",
            "㉠의 이유로 가장 적절한 것은?\n",
            "㉠, ㉡에 대한 설명으로 가장 적절한 것은?\n",
            "㉠, ㉡에 대한 설명으로 가장 적절한 것은?\n"
          ]
        }
      ],
      "source": [
        "query = '27. ㉠에 대한 이해로 가장 적절한 것은?'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjzeM-Lri-_-",
        "outputId": "6cdc445f-c189-4ea4-ee3d-032168f60013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 25. 문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?\n",
            "- similar\n",
            "문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?\n",
            "[A]를 바탕으로 의 ⓐ～ⓔ의 밑줄 친 부분을 이해한 내용으로 적절하지 않은 것은?\n",
            "문맥을 고려할 때 ㉠의 의미를 파악한 내용으로 가장 적절한 것은?\n",
            "대화의 흐름을 고려할 때, ㉠～㉤에 대한 설명으로 적절하지 않은 것은?\n",
            "다음을 고려할 때, [A]에 들어갈 내용으로 가장 적절한 것은?\n"
          ]
        }
      ],
      "source": [
        "query = '25. 문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDCdcpzsi-__"
      },
      "source": [
        "## 문서 분석 완료!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cUSetNZTi-__"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4T7ATsvoC5ez"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "nlp_4_1_document_vector_2_colab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}