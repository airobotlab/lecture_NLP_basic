{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pV286PDi-_u"
      },
      "source": [
        "# 문서 벡터화 알고리즘 실습\n",
        "\n",
        "220603\n",
        "\n",
        "- 1) BOW\n",
        "- 2) DTW\n",
        "- 3) TF-IDF\n",
        "- 4) 문서 검색 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKJFFDbDi-_x",
        "outputId": "3ab2e5c5-4380-4ef2-e369-5d8dbc47db62",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# install\n",
        "!python -m pip install konlpy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "tECk1yKL-07X"
      },
      "source": [
        "## 1) BoW (Bag of Words) 기반 문서 벡터화\n",
        "\n",
        "- [ref](https://wikidocs.net/22650)\n",
        "\n",
        "Bag of Words (단어들의 가방이)\n",
        "- 단어들의 순서는 전혀 고려 없이 단어들의 출현 빈도(frequency)만으로 텍스트를 수치화\n",
        "- 모든 텍스트 문서를 가방에 넣고 섞은 후 단어를 섞는다\n",
        "\n",
        "BoW를 만드는 과정을 이렇게 두 가지 과정으로 생각해보겠습니다.\n",
        "\n",
        "- 1) 각 단어에 고유한 정수 인덱스를 부여\n",
        "- 2) 각 단어의 출현 빈도수 저장\n",
        "- 불용어를 제거하면 더 좋은 성능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "id": "cY-DFrWti-_z"
      },
      "outputs": [],
      "source": [
        "## bow function\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "def build_bag_of_words(document):\n",
        "    # 온점 제거 및 형태소 분석\n",
        "    document = document.replace('.', '')\n",
        "    tokenized_document = okt.morphs(document)\n",
        "\n",
        "    word_to_index = {}\n",
        "    bow = []\n",
        "    for word in tokenized_document:\n",
        "        if word not in word_to_index.keys():\n",
        "            word_to_index[word] = len(word_to_index)\n",
        "            # BoW에 전부 기본값 1을 넣는다.\n",
        "            bow.insert(len(word_to_index) - 1, 1)\n",
        "        else:\n",
        "            # 재등장하는 단어의 인덱스\n",
        "            index = word_to_index.get(word)\n",
        "            # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
        "            bow[index] = bow[index] + 1\n",
        "\n",
        "    return word_to_index, bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "zaR6xMnqi-_0",
        "outputId": "181a5d5c-0ce0-4eb9-a87b-bc0e537b21b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "## 예시 1)\n",
        "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "vocab, bow = build_bag_of_words(doc1)\n",
        "\n",
        "print('input: %s'%(doc1))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "GLu4G5yYi-_1",
        "outputId": "0a531829-9a19-416c-da5c-c07e0a67f621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "## 예시 2)\n",
        "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
        "\n",
        "vocab, bow = build_bag_of_words(doc2)\n",
        "\n",
        "print('input: %s'%(doc2))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "XkkkJ00xi-_1",
        "outputId": "8b94c1d1-78f1-442b-bcdf-41b7cf0e704c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "## 예시 3) 문서1과 문서2를 합쳐서 구할 수 있음\n",
        "doc3 = doc1 + ' ' + doc2\n",
        "vocab, bow = build_bag_of_words(doc3)\n",
        "\n",
        "print('input: %s'%(doc3))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "VINGWzrNi-_2",
        "outputId": "46236ba1-c18a-4308-c15a-08898e3f5906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: [('기준', 0), ('느끼는', 1), ('느낀다', 2), ('다르다', 3), ('물가상승률', 4), ('발표', 5), ('상품', 6), ('소비', 7), ('소비자', 8), ('으로', 9), ('정부', 10), ('주로', 11), ('하는', 12)]\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector: [[1 1 1 1 3 1 1 1 2 1 1 1 2]]\n"
          ]
        }
      ],
      "source": [
        "## 3. CountVectorizer 클래스로 BoW 만들기\n",
        "# 단어의 빈도를 Count하여 Vector로 만드는 사이킷런의 CountVectorizer를 이용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# corpus = ['you know I want your love. because I love you.']\n",
        "corpus = [' '.join(okt.morphs(doc3))]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "\n",
        "bow = vector.fit_transform(corpus).toarray()\n",
        "vocab = sorted(vector.vocabulary_.items())\n",
        "\n",
        "print('input: %s'%(doc3))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:', bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "pXsgP6ZPi-_3"
      },
      "source": [
        "## 2) 문서 단어 행렬(Document-Term Matrix, DTM) 기반 문서 벡터화\n",
        "\n",
        "- [ref](https://wikidocs.net/31698)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "hidden": true,
        "id": "dpqunYJ7i-_4"
      },
      "outputs": [],
      "source": [
        "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
        "doc3 = doc1 + ' ' + doc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "URtC19hRi-_4",
        "outputId": "2433a8d1-b035-4c1e-fb73-1072a07240dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: ['정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.', '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.', '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.']\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: [('기준으로', 0), ('느끼는', 1), ('느낀다', 2), ('다르다', 3), ('물가상승률과', 4), ('물가상승률은', 5), ('물가상승률을', 6), ('발표하는', 7), ('상품을', 8), ('소비자가', 9), ('소비자는', 10), ('소비하는', 11), ('정부가', 12), ('주로', 13)]\n",
            "\n",
            "2) 각 단어의 출현 빈도수 저장\n",
            "   =>bag of words vector:\n",
            " [[0 1 0 1 1 1 0 1 0 1 0 0 1 0]\n",
            " [1 0 1 0 0 0 1 0 1 0 1 1 0 1]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "## DTW\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [doc1, doc2, doc3]\n",
        "vector = CountVectorizer()\n",
        "\n",
        "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "DTW = vector.fit_transform(corpus).toarray()\n",
        "# 각 단어와 맵핑된 인덱스 출력\n",
        "vocab = sorted(vector.vocabulary_.items())\n",
        "\n",
        "print('input: %s'%(corpus))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 출현 빈도수 저장\\n   =>bag of words vector:\\n', DTW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "hidden": true,
        "id": "qydHVtnTi-_5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "pyPrDUuyi-_5"
      },
      "source": [
        "## 3) TF-IDF 기반 문서 벡터화\n",
        "\n",
        "- [ref](https://wikidocs.net/31698)\n",
        "\n",
        "\n",
        "- (1) TF(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "    - TF는 각 문서에서 각 단어의 등장 빈도\n",
        "    \n",
        "- (2) DF(t) : 특정 단어 t가 등장한 문서의 수\n",
        "\n",
        "- (3) IDF(d, t) : df(t)에 반비례값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "hmhQq4_fi-_5",
        "outputId": "ab54c8fb-b0d9-4424-c16c-76fe5e2e7baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: ['정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.', '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.', '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.']\n",
            "\n",
            "1) 각 단어에 고유한 정수 인덱스를 부여\n",
            "   =>vocab: [('기준으로', 0), ('느끼는', 1), ('느낀다', 2), ('다르다', 3), ('물가상승률과', 4), ('물가상승률은', 5), ('물가상승률을', 6), ('발표하는', 7), ('상품을', 8), ('소비자가', 9), ('소비자는', 10), ('소비하는', 11), ('정부가', 12), ('주로', 13)]\n",
            "\n",
            "2) 각 단어의 TF-IDF\n",
            "   =>bag of words vector:\n",
            " [[0.         0.37796447 0.         0.37796447 0.37796447 0.37796447\n",
            "  0.         0.37796447 0.         0.37796447 0.         0.\n",
            "  0.37796447 0.        ]\n",
            " [0.37796447 0.         0.37796447 0.         0.         0.\n",
            "  0.37796447 0.         0.37796447 0.         0.37796447 0.37796447\n",
            "  0.         0.37796447]\n",
            " [0.26726124 0.26726124 0.26726124 0.26726124 0.26726124 0.26726124\n",
            "  0.26726124 0.26726124 0.26726124 0.26726124 0.26726124 0.26726124\n",
            "  0.26726124 0.26726124]]\n"
          ]
        }
      ],
      "source": [
        "# tf-idf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# corpus = [\n",
        "#     'you know I want your love',\n",
        "#     'I like you',\n",
        "#     'what should I do ',    \n",
        "# ]\n",
        "corpus = [doc1, doc2, doc3]\n",
        "\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "\n",
        "TFIDF = tfidfv.transform(corpus).toarray()\n",
        "vocab = sorted(tfidfv.vocabulary_.items())\n",
        "\n",
        "print('input: %s'%(corpus))\n",
        "print('\\n1) 각 단어에 고유한 정수 인덱스를 부여\\n   =>vocab:', vocab)\n",
        "print('\\n2) 각 단어의 TF-IDF\\n   =>bag of words vector:\\n', TFIDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "fQgZ8YGki-_6"
      },
      "source": [
        "## 4) 벡터 유사도\n",
        "\n",
        "- [url](https://wikidocs.net/24603)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "VXzcl2APi-_6",
        "outputId": "a2cf60d3-06c4-4f5f-df4e-2621f0cf0155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###\n",
            "(L1)문서1과 문서Q의 거리 : 3\n",
            "(L1)문서2과 문서Q의 거리 : 4\n",
            "(L1)문서3과 문서Q의 거리 : 4\n",
            "\n",
            "###\n",
            "(L2)문서1과 문서Q의 거리 : 2.23606797749979\n",
            "(L2)문서2과 문서Q의 거리 : 3.1622776601683795\n",
            "(L2)문서3과 문서Q의 거리 : 2.449489742783178\n",
            "\n",
            "###\n",
            "(infinity)문서1과 문서Q의 거리 : 2\n",
            "(infinity)문서2과 문서Q의 거리 : 3\n",
            "(infinity)문서3과 문서Q의 거리 : 2\n",
            "\n",
            "###\n",
            "(cosine)문서1과 문서Q의 거리 : 0.9258200997725515\n",
            "(cosine)문서2과 문서Q의 거리 : 0.5962847939999439\n",
            "(cosine)문서3과 문서Q의 거리 : 0.8006407690254358\n"
          ]
        }
      ],
      "source": [
        "# 4.1) L1, L2(Euclidean distance), infinity, cosine distance\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def get_L1_distance(x,y):   \n",
        "    return np.sum(np.abs(x-y))\n",
        "\n",
        "def get_L2_distance(x,y):\n",
        "    return np.sqrt(np.sum((x-y)**2))\n",
        "\n",
        "def get_infinity_distance(x, y):\n",
        "    return np.max(np.abs(x-y))\n",
        "\n",
        "def get_cosine_similarity(x, y):\n",
        "    return dot(x, y)/(norm(x)*norm(y))\n",
        "\n",
        "\n",
        "doc1 = np.array((2,3,0,1))\n",
        "doc2 = np.array((1,2,3,1))\n",
        "doc3 = np.array((2,1,2,2))\n",
        "\n",
        "docQ = np.array((1,1,0,1))\n",
        "\n",
        "print('###\\n(L1)문서1과 문서Q의 거리 :', get_L1_distance(doc1, docQ))\n",
        "print('(L1)문서2과 문서Q의 거리 :', get_L1_distance(doc2, docQ))\n",
        "print('(L1)문서3과 문서Q의 거리 :', get_L1_distance(doc3, docQ))\n",
        "\n",
        "print('\\n###\\n(L2)문서1과 문서Q의 거리 :', get_L2_distance(doc1, docQ))\n",
        "print('(L2)문서2과 문서Q의 거리 :', get_L2_distance(doc2, docQ))\n",
        "print('(L2)문서3과 문서Q의 거리 :', get_L2_distance(doc3, docQ))\n",
        "\n",
        "print('\\n###\\n(infinity)문서1과 문서Q의 거리 :', get_infinity_distance(doc1, docQ))\n",
        "print('(infinity)문서2과 문서Q의 거리 :', get_infinity_distance(doc2, docQ))\n",
        "print('(infinity)문서3과 문서Q의 거리 :', get_infinity_distance(doc3, docQ))\n",
        "\n",
        "print('\\n###\\n(cosine)문서1과 문서Q의 거리 :', get_cosine_similarity(doc1, docQ))\n",
        "print('(cosine)문서2과 문서Q의 거리 :', get_cosine_similarity(doc2, docQ))\n",
        "print('(cosine)문서3과 문서Q의 거리 :', get_cosine_similarity(doc3, docQ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "pXhFg5Qli-_6",
        "outputId": "7197362c-1c9f-4060-eaaa-f00495b793f7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서1 : ['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
            "문서2 : ['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n",
            "문서1과 문서2의 합집합 : {'everyone', 'holder', 'coupon', 'like', 'passport', 'apple', 'love', 'you', 'likey', 'watch', 'banana', 'card'}\n",
            "문서1과 문서2의 교집합 : {'banana', 'apple'}\n",
            "자카드 유사도 : 0.16666666666666666\n",
            "자카드 유사도 : 0.166667\n"
          ]
        }
      ],
      "source": [
        "# 4.2) 자카드 유사도(Jaccard similarity)\n",
        "def get_jaccard_distance(x, y):\n",
        "    # 합집합\n",
        "    union = set(x).union(set(y))\n",
        "    # 교집합\n",
        "    intersection = set(x).intersection(set(y))\n",
        "    # 교집합/합집합\n",
        "    distance = (len(intersection) / len(union))\n",
        "    return distance\n",
        "\n",
        "\n",
        "doc1 = \"apple banana everyone like likey watch card holder\"\n",
        "doc2 = \"apple banana coupon passport love you\"\n",
        "\n",
        "# doc1 = \"apple banana everyone like likey\"\n",
        "# doc2 = \"apple banana everyone like\"\n",
        "\n",
        "# 토큰화\n",
        "tokenized_doc1 = doc1.split()\n",
        "tokenized_doc2 = doc2.split()\n",
        "\n",
        "print('문서1 :',tokenized_doc1)\n",
        "print('문서2 :',tokenized_doc2)\n",
        "\n",
        "union = set(tokenized_doc1).union(set(tokenized_doc2))\n",
        "print('문서1과 문서2의 합집합 :',union)\n",
        "\n",
        "intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))\n",
        "print('문서1과 문서2의 교집합 :',intersection)\n",
        "\n",
        "print('자카드 유사도 :', len(intersection)/len(union))\n",
        "print('자카드 유사도 : %f' % get_jaccard_distance(tokenized_doc1, tokenized_doc2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "yH93gqFsi-_7",
        "outputId": "776646f3-e3a3-4405-d99c-8eea8787c491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서 1과 문서2의 유사도 : 0.6666666666666667\n",
            "문서 1과 문서3의 유사도 : 0.6666666666666667\n",
            "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "## 4.3) 코사인 유사도(Cosine Similarity)\n",
        "# 벡터의 방향(패턴)에 초점을 두므로 코사인 유사도는 문서의 길이가 다른 상황에서 비교적 공정한 비교\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def get_cosine_similarity(x, y):\n",
        "    return dot(x, y)/(norm(x)*norm(y))\n",
        "\n",
        "doc1 = np.array([0, 1, 1, 1])\n",
        "doc2 = np.array([1, 0, 1, 1])\n",
        "doc3 = np.array([2, 0, 2, 2])\n",
        "\n",
        "print('문서 1과 문서2의 유사도 :', get_cosine_similarity(doc1, doc2))\n",
        "print('문서 1과 문서3의 유사도 :', get_cosine_similarity(doc1, doc3))\n",
        "print('문서 2와 문서3의 유사도 :', get_cosine_similarity(doc2, doc3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "bCtGKCoK_mkJ"
      },
      "source": [
        "## 5) Co-Occurrance matrix (동시 발생 행렬)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f6n41Jl_mkJ",
        "outputId": "49922363-b97b-454c-d680-8abc94ac94ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('굳 ㅋ', 1), ('GDNTOPCLASSINTHECLUB', 0)]\n",
            "['굳 ㅋ', 'GDNTOPCLASSINTHECLUB', '뭐 야 이 평점 들 은 .... 나쁘진 않지만 10 점 짜 리 는 더 더욱 아니잖아', '지루하지는 않은데 완전 막장 임 ... 돈 주고 보기 에는 ....', '3 D 만 아니었어도 별 다섯 개 줬을텐데 .. 왜 3 D 로 나와서 제 심기 를 불편하게 하죠 ??']\n",
            "['', '', '뭐 이 평점 점 리 더 더욱', '완전 막장 임 돈 보기', '만 별 다섯 개 왜 로 제 심기']\n"
          ]
        }
      ],
      "source": [
        "## read nsmc data\n",
        "# NSMC 데이터 로드, 5만\n",
        "import pandas as pd\n",
        "data_nsmc = pd.read_table('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n",
        "\n",
        "train_pair = [(row[1], row[2]) for _, row in data_nsmc.iterrows() if type(row[1]) == str]  # nan 제거\n",
        "print(train_pair[:2])\n",
        "\n",
        "#  문장 및 라벨 데이터 추출\n",
        "# train_data  = [pair[0] for pair in train_pair][:1000]\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "train_data_morph  = [' '.join(okt.morphs(pair[0])) for pair in train_pair[:1000]]\n",
        "train_data_noun  = [' '.join(okt.nouns(pair[0])) for pair in train_pair[:1000]]  # 명사만 추출\n",
        "print(train_data_morph[:5])\n",
        "print(train_data_noun[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "code_folding": [
          1,
          19,
          35
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48WbpNl7_mkK",
        "outputId": "3605f1fc-5a7d-4e94-bf7c-d88c9e8de3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "굳 ㅋ GDNTOPCLASSINTHECLUB 뭐 야 이 평점 들 은 .... 나쁘진 않지만\n",
            "자주 등장하는   단어: [('.', 446), ('이', 389), ('영화', 344), ('의', 234), ('..', 218)]\n",
            "자주 등장안하는 단어: [('존재도', 1), ('멋지지도', 1), ('밋밋하다고밖에', 1), ('할말이', 1), ('쓰는', 1)]\n"
          ]
        }
      ],
      "source": [
        "# get word frequency\n",
        "def get_coocurrance_matrix_df(list_sentence, K=30):\n",
        "\n",
        "    string = ' '.join((' '.join(list_sentence)).split())\n",
        "    print(string[:50])\n",
        "    \n",
        "    from collections import Counter\n",
        "    count = Counter(string.split())\n",
        "    count_top_k = count.most_common()\n",
        "\n",
        "    print('자주 등장하는   단어: %s'%count_top_k[:5])\n",
        "    print('자주 등장안하는 단어: %s'%count_top_k[-5:])\n",
        "\n",
        "    count_top_k = count_top_k[:K]\n",
        "    count_top_k_dict = dict(count_top_k)\n",
        "\n",
        "    # get co-occurance matrix\n",
        "    vocab = [tmp[0] for tmp in count_top_k]  # ['.', '이', '영화', '의', '..', '...', '에', '가', '을', '도']\n",
        "\n",
        "    def get_context_counts(input_string, vocab, window_size=2):\n",
        "        from collections import defaultdict\n",
        "        context_cnt = defaultdict(int)\n",
        "\n",
        "        for line in input_string:\n",
        "            words = line.split()\n",
        "\n",
        "            for i, w in enumerate(words):\n",
        "                if w in vocab:\n",
        "                    for c in words[i - window_size : i + window_size]:\n",
        "                        if w != c:\n",
        "                            context_cnt[(w, c)] += 1\n",
        "\n",
        "        return context_cnt\n",
        "\n",
        "\n",
        "    def get_coocurrance_matrix(word2word_cnt, vocab):\n",
        "        word_matrix = []\n",
        "        for word1 in vocab:\n",
        "            list_word_cnt = []\n",
        "            for word2 in vocab:\n",
        "                try:\n",
        "                    count = word2word_cnt[(word1, word2)]  # 단어와 단어 pair가 있으면 숫자를, 없으면(같은 단어면) 0으로 채운다\n",
        "                except:\n",
        "                    count = -999\n",
        "                list_word_cnt.append(count)\n",
        "\n",
        "            word_matrix.append(list_word_cnt)\n",
        "        return word_matrix\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    word2word_cnt = get_context_counts(list_sentence, vocab, window_size=4)\n",
        "    coocurrance_matrix = get_coocurrance_matrix(word2word_cnt, vocab)\n",
        "\n",
        "    coocurrance_matrix_df = pd.DataFrame(coocurrance_matrix, index=vocab, columns=vocab)\n",
        "    return coocurrance_matrix_df\n",
        "\n",
        "\n",
        "morph_coocurrance_matrix_df = get_coocurrance_matrix_df(list_sentence=train_data_morph, K=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_8sw-wi_mkK",
        "outputId": "ffa1f782-c9f7-41cf-ac74-abbcf60c3162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뭐 이 평점 점 리 더 더욱 완전 막장 임 돈 보기 만 별 다섯 개 왜 로 제 심기 음악 \n",
            "자주 등장하는   단어: [('영화', 344), ('정말', 65), ('것', 58), ('점', 54), ('이', 53)]\n",
            "자주 등장안하는 단어: [('디젤', 1), ('개똥폼', 1), ('잡고', 1), ('디아블로', 1), ('존재도', 1)]\n"
          ]
        }
      ],
      "source": [
        "# 명사만\n",
        "noun_coocurrance_matrix_df = get_coocurrance_matrix_df(list_sentence=train_data_noun, K=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "code_folding": [
          0
        ],
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7TY8e0b_mkK",
        "outputId": "048fec43-02d8-41ed-c7bf-ef0ca2807a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### morph\n",
            "## L1 distance\n",
            "영화 : 0.00, 이 : 235.00, 들 : 298.00, .. : 312.00, 도 : 315.00, 을 : 321.00, 의 : 328.00, . : 335.00, 가 : 341.00, 에 : 345.00\n",
            "\n",
            "## L2 distance\n",
            "영화 : 0.00, 도 : 72.64, 이 : 73.80, 들 : 74.71, 의 : 78.46, 가 : 78.54, 을 : 78.80, 는 : 81.50, .. : 83.34, 은 : 85.99\n",
            "\n",
            "## Inf distance\n",
            "영화 : 0.00, 가 : 29.00, 의 : 32.00, 도 : 32.00, 을 : 37.00, 는 : 37.00, 은 : 44.00, 이 : 45.00, 다 : 45.00, 들 : 47.00\n",
            "\n",
            "## Cosine distance\n",
            "영화 : 1.00, 도 : 0.89, 에서 : 0.86, 너무 : 0.85, 만 : 0.85, 점 : 0.84, 평점 : 0.83, 은 : 0.82, , : 0.81, 들 : 0.81\n",
            "\n",
            "\n",
            "#### noun\n",
            "## L1 distance\n",
            "영화 : 0.00, 정말 : 173.00, 평점 : 175.00, 드라마 : 175.00, 것 : 177.00, 보고 : 178.00, 점 : 180.00, 재미 : 180.00, 그 : 184.00, 더 : 186.00\n",
            "\n",
            "## L2 distance\n",
            "영화 : 0.00, 점 : 36.72, 드라마 : 36.81, 정말 : 37.03, 재미 : 37.09, 보고 : 37.23, 평점 : 37.30, 그 : 37.34, 것 : 37.54, 더 : 37.82\n",
            "\n",
            "## Inf distance\n",
            "영화 : 0.00, 점 : 15.00, 정말 : 16.00, 생각 : 16.00, 사람 : 16.00, 더 : 16.00, 보고 : 16.00, 거 : 17.00, 이건 : 17.00, 감독 : 17.00\n",
            "\n",
            "## Cosine distance\n",
            "영화 : 1.00, 드라마 : 0.61, 재미 : 0.55, 스토리 : 0.50, 그 : 0.50, 점 : 0.47, 평점 : 0.46, 보고 : 0.46, 더 : 0.45, 정말 : 0.44\n"
          ]
        }
      ],
      "source": [
        "def get_distance_from_cooccurrence_matrix(coocurrance_matrix_df, K=10, query='영화', metric=get_cosine_similarity, is_ascending=True):\n",
        "\n",
        "    word_cooccurrance_vector = coocurrance_matrix_df.loc[query].values    # df에서 해당하는 단어의 행값을 가져온다\n",
        "    # print(word_cooccurrance_vector)\n",
        "\n",
        "    distances = coocurrance_matrix_df.apply(\n",
        "        lambda x: metric(word_cooccurrance_vector, x.values),\n",
        "        axis=1,\n",
        "    ).sort_values(ascending=is_ascending)[:K]\n",
        "\n",
        "    list_key = distances.keys().tolist()\n",
        "    list_value = distances.tolist()\n",
        "\n",
        "    tmp = ['%s : %.2f'%(list_key[idx], list_value[idx]) for idx in range(len(list_key))]\n",
        "    print(', '.join(tmp))\n",
        "    return\n",
        "\n",
        "query = '영화'\n",
        "\n",
        "print('#### morph')\n",
        "print('## L1 distance')\n",
        "get_distance_from_cooccurrence_matrix(morph_coocurrance_matrix_df, query=query, metric=get_L1_distance)\n",
        "print('\\n## L2 distance')\n",
        "get_distance_from_cooccurrence_matrix(morph_coocurrance_matrix_df, query=query, metric=get_L2_distance)\n",
        "print('\\n## Inf distance')\n",
        "get_distance_from_cooccurrence_matrix(morph_coocurrance_matrix_df, query=query, metric=get_infinity_distance)\n",
        "print('\\n## Cosine distance')\n",
        "get_distance_from_cooccurrence_matrix(morph_coocurrance_matrix_df, query=query, metric=get_cosine_similarity, is_ascending=False)\n",
        "\n",
        "print('\\n\\n#### noun')\n",
        "print('## L1 distance')\n",
        "get_distance_from_cooccurrence_matrix(noun_coocurrance_matrix_df, query=query, metric=get_L1_distance)\n",
        "print('\\n## L2 distance')\n",
        "get_distance_from_cooccurrence_matrix(noun_coocurrance_matrix_df, query=query, metric=get_L2_distance)\n",
        "print('\\n## Inf distance')\n",
        "get_distance_from_cooccurrence_matrix(noun_coocurrance_matrix_df, query=query, metric=get_infinity_distance)\n",
        "print('\\n## Cosine distance')\n",
        "get_distance_from_cooccurrence_matrix(noun_coocurrance_matrix_df, query=query, metric=get_cosine_similarity, is_ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ToIk_p0qi-_7"
      },
      "source": [
        "## 6) BM25, 유사도 기반 문서 검색\n",
        "\n",
        "- [url](https://github.com/dorianbrown/rank_bm25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "code_folding": [
          0,
          22,
          23,
          37,
          60,
          74,
          84,
          85,
          91,
          113,
          143
        ],
        "hidden": true,
        "id": "yI4weB7Zi-_7"
      },
      "outputs": [],
      "source": [
        "## load, BM25 구현코드, https://github.com/dorianbrown/rank_bm25\n",
        "# [비슷한 문장들의 idx], [비슷한 문장듯] = bm25_model.get_top_n(tokenized_query, question_list, n=5)\n",
        "'''\n",
        "- 사용법\n",
        "corpus = [\n",
        "    \"Hello there good man!\",\n",
        "    \"It is quite windy in London\",\n",
        "    \"How is the weather today?\"\n",
        "]\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "query = \"windy London\"\n",
        "tokenized_query = query.split(\" \")\n",
        "doc_scores = bm25.get_scores(tokenized_query)  # array([0.        , 0.93729472, 0.        ])\n",
        "bm25.get_top_n(tokenized_query, corpus, n=1)  # 비슷한 문장들의 idx], [비슷한 문장듯]\n",
        "'''\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import pandas as pd\n",
        "\n",
        "class BM25:\n",
        "    def __init__(self, corpus, tokenizer=None):\n",
        "        self.corpus_size = len(corpus)\n",
        "        self.avgdl = 0\n",
        "        self.doc_freqs = []\n",
        "        self.idf = {}\n",
        "        self.doc_len = []\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if tokenizer:\n",
        "            corpus = self._tokenize_corpus(corpus)\n",
        "\n",
        "        nd = self._initialize(corpus)\n",
        "        self._calc_idf(nd)\n",
        "\n",
        "    def _initialize(self, corpus):\n",
        "        nd = {}  # word -> number of documents with word\n",
        "        num_doc = 0\n",
        "        for document in corpus:\n",
        "            self.doc_len.append(len(document))\n",
        "            num_doc += len(document)\n",
        "\n",
        "            frequencies = {}\n",
        "            for word in document:\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 0\n",
        "                frequencies[word] += 1\n",
        "            self.doc_freqs.append(frequencies)\n",
        "\n",
        "            for word, freq in frequencies.items():\n",
        "                try:\n",
        "                    nd[word]+=1\n",
        "                except KeyError:\n",
        "                    nd[word] = 1\n",
        "\n",
        "        self.avgdl = num_doc / self.corpus_size\n",
        "        return nd\n",
        "\n",
        "    def _tokenize_corpus(self, corpus):\n",
        "        pool = Pool(cpu_count())\n",
        "        tokenized_corpus = pool.map(self.tokenizer, corpus)\n",
        "        return tokenized_corpus\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_top_n(self, query, documents, n=5):\n",
        "\n",
        "        # index도 출력되게 수정\n",
        "        assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "\n",
        "        scores = self.get_scores(query)\n",
        "        top_n = np.argsort(scores)[::-1][:n]\n",
        "        return top_n.tolist(), [documents[i] for i in top_n]  # wygo 수정, idx도 출력되도록\n",
        "\n",
        "\n",
        "class BM25Okapi(BM25):\n",
        "    def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.epsilon = epsilon\n",
        "        super().__init__(corpus, tokenizer)\n",
        "\n",
        "    def _calc_idf(self, nd):\n",
        "        \"\"\"\n",
        "        Calculates frequencies of terms in documents and in corpus.\n",
        "        This algorithm sets a floor on the idf values to eps * average_idf\n",
        "        \"\"\"\n",
        "        # collect idf sum to calculate an average idf for epsilon value\n",
        "        idf_sum = 0\n",
        "        # collect words with negative idf to set them a special epsilon value.\n",
        "        # idf can be negative if word is contained in more than half of documents\n",
        "        negative_idfs = []\n",
        "        for word, freq in nd.items():\n",
        "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
        "            self.idf[word] = idf\n",
        "            idf_sum += idf\n",
        "            if idf < 0:\n",
        "                negative_idfs.append(word)\n",
        "        self.average_idf = idf_sum / len(self.idf)\n",
        "\n",
        "        eps = self.epsilon * self.average_idf\n",
        "        for word in negative_idfs:\n",
        "            self.idf[word] = eps\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        \"\"\"\n",
        "        The ATIRE BM25 variant uses an idf function which uses a log(idf) score. To prevent negative idf scores,\n",
        "        this algorithm also adds a floor to the idf value of epsilon.\n",
        "        See [Trotman, A., X. Jia, M. Crane, Towards an Efficient and Effective Search Engine] for more info\n",
        "        :param query:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        score = np.zeros(self.corpus_size)\n",
        "        doc_len = np.array(self.doc_len)\n",
        "        for q in query:\n",
        "            q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
        "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "        return score\n",
        "\n",
        "    def get_batch_scores(self, query, doc_ids):\n",
        "        \"\"\"\n",
        "        Calculate bm25 scores between query and subset of all docs\n",
        "        \"\"\"\n",
        "        assert all(di < len(self.doc_freqs) for di in doc_ids)\n",
        "        score = np.zeros(len(doc_ids))\n",
        "        doc_len = np.array(self.doc_len)[doc_ids]\n",
        "        for q in query:\n",
        "            q_freq = np.array([(self.doc_freqs[di].get(q) or 0) for di in doc_ids])\n",
        "            score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n",
        "                                               (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "        return score.tolist()\n",
        "\n",
        "    \n",
        "def IR_BM25(query, bm25_model, tokenizer='space', n=5):\n",
        "    '''\n",
        "    input\n",
        "        query: '. 윗글에서 확인할 수 있는 ㉠의 방법이 아닌 것은?'\n",
        "        bm25_model: BM25Okapi(tokenized_corpus)\n",
        "        tokenizer: mecab 형태소 분석기\n",
        "    '''\n",
        "    # 쿼리 프리프로세싱\n",
        "#     query = '27. ㉠에 대한 이해로 가장 적절한 것은?'\n",
        "#     query = '1. 윗글에서 확인할 수 있는 ㉠의 방법이 아닌 것은?'\n",
        "\n",
        "    if tokenizer=='space':\n",
        "        tokenized_query = query.split()\n",
        "    else:\n",
        "        tokenized_query = tokenizer(query)\n",
        "    \n",
        "    doc_representation = bm25_model.get_scores(tokenized_query)  # array([0.        , 0.93729472, 0.        ])\n",
        "\n",
        "    # 유사문장 가져오기\n",
        "    similar_idx, similar_sentences = bm25_model.get_top_n(tokenized_query, question_list, n)\n",
        "\n",
        "    print('- query : %s' % (query))\n",
        "    print('- similar\\n%s' % ('\\n'.join(similar_sentences)))\n",
        "    \n",
        "    return similar_idx, similar_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "L5oqwGkOi-_9",
        "outputId": "1a00c9dc-3ced-41dd-ef09-221181c6422f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45. <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지않은 것은? [3점]\n",
            "번호 제거 ==>>  <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지않은 것은? [3점]\n"
          ]
        }
      ],
      "source": [
        "# 0) DB에 있는 문제들을 가져와서 앞의 번호를 제거한 후 list를 만든다\n",
        "question_list = ['8. (나)에 활용된 글쓰기 전략으로 적절하지 않은 것은?',\n",
        "                 '9. <보기>는 (나)의 ‘학생’이 ‘초고’를 보완하기 위해 추가로 수집한 자료이다. 자료 활용 방안으로 적절하지 않은 것은?',\n",
        "                 '10. 다음은 (나)의 ‘학생’이 ‘초고’를 고쳐 쓰는 과정에서 수행한 학습 활동이다. [A]에 들어갈 내용으로 가장 적절한 것은?',\n",
        "                 '11. ㉠과 ㉡을 모두 충족하는 단어만을 <보기>에서 있는 대로 고른 것은?',\n",
        "                 '12. 윗글과 <보기>를 바탕으로 추론한 내용으로 적절하지 않은 것은?',\n",
        "                 '13. ⓐ～ⓔ는 잘못된 표기를 바르게 고친 것이다. 고치는 과정에서 해당 단어에 적용된 용언 활용의 예로 적절하지 않은 것은?',\n",
        "                 '14. <학습 활동>을 수행한 결과로 적절하지 않은 것은? [3점]',\n",
        "                 '15. <보기>의 ㉠과 ㉡에 들어갈 말로 적절한 것은?',\n",
        "                 '16. (가), (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '17. (가)의 ‘박제가’와 ‘이덕무’에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '18. 평등견 에 대한 이해로 가장 적절한 것은?',\n",
        "                 '19. 문맥을 고려할 때 ㉠의 의미를 파악한 내용으로 가장 적절한 것은?',\n",
        "                 '20. <보기>는 (가)에 제시된 \\U000f0854북학의\\U000f0855의 일부이다. [A]와 (나)를 참고하여 <보기>에 대해 비판적 읽기를 수행한 학생의 반응으로 적절하지 않은 것은? [3점]',\n",
        "                 '21. 문맥상 ⓐ～ⓔ와 바꿔 쓰기에 가장 적절한 것은?',\n",
        "                 '22. [A]와 [B]의 서술상 특징에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '23. 윗글에 대한 이해로 가장 적절한 것은?',\n",
        "                 '24. ⓐ, ⓑ에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '25. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '26. 윗글에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '27. ㉠에 대한 이해로 가장 적절한 것은?',\n",
        "                 '28. 다음은 [A]에 제시된 예를 활용하여, 예약의 유형에 따라 예약상 권리자가 요구할 수 있는 급부에 대해 정리한 것이다. ㄱ～ㄷ에 들어갈 내용을 올바르게 짝지은 것은?',\n",
        "                 '29. 윗글을 참고할 때, <보기>의 ㉮에 대한 이해로 적절하지 않은 것은? [3점]',\n",
        "                 '30. 문맥상 ⓐ～ⓔ의 단어와 가장 가까운 의미로 쓰인 것은?',\n",
        "                 '31. 윗글의 서술상 특징으로 가장 적절한 것은?',\n",
        "                 '32. 윗글의 내용에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '33. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '34. 윗글에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '35. 모델링 에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '36. ㉠에 대한 추론으로 적절한 것은?',\n",
        "                 '37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]',\n",
        "                 '38. (가)와 (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '39. <보기>를 바탕으로 (가)를 감상한 내용으로 적절하지 않은 것은?',\n",
        "                 '40. <보기>를 바탕으로 (나), (다)를 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '41. (가)와 (다)를 비교하여 이해한 내용으로 가장 적절한 것은?',\n",
        "                 '42. (다)에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '43. (가)에 대한 이해로 가장 적절한 것은?',\n",
        "                 '44. ㉠～㉤의 의미를 고려하여 (나)를 감상한 내용으로 적절하지 않은 것은?',\n",
        "                 '45. <보기>를 참고하여 (가)와 (나)를 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '1. 윗글에서 확인할 수 있는 ㉠의 방법이 아닌 것은?',\n",
        "                 '2. 윗글을 바탕으로 <보기>를 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '3. 다음은 윗글을 읽은 학생의 반응이다. 이에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '4. 다음은 (가)와 (나)를 읽은 학생이 작성한 학습 활동지의 일부 이다. ㄱ～ㅁ에 들어갈 내용으로 적절하지 않은 것은?',\n",
        "                 '5. 윗글에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '6. [A]에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '7. ㉠, ㉡에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '8. 는 윗글의 주제와 관련한 동서양 학자들의 견해이다. 윗글을 읽은 학생이 에 대해 보인 반응으로 적절하지 않은 것은? [3점]',\n",
        "                 '9. ⓐ와 문맥상 의미가 가장 가까운 것은?',\n",
        "                 '10. 윗글에서 베카리아의 관점으로 보기 어려운 것은?',\n",
        "                 '11. ㉠에 대한 설명으로 적절하지 않은 것은?',\n",
        "                 '12. 윗글을 바탕으로 베카리아의 입장을 추론한 내용으로 가장 적절한 것은? [3점]',\n",
        "                 '13. 문맥상 ⓐ～ⓔ와 바꿔 쓰기에 적절하지 않은 것은?',\n",
        "                 '14. 윗글에서 알 수 있는 내용으로 적절하지 않은 것은?',\n",
        "                 '15. ㉠과 ㉡에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '16. 어느 바이러스 감염증의 진단 검사에 PCR를 이용하려고 한다. 윗글을 읽고 이해한 반응으로 가장 적절한 것은?',\n",
        "                 '17. [A]를 바탕으로 의 실험 상황을 가정하고 와 같이 예상 결과를 추론하였다. ㉮～㉰에 들어갈 말로 적절한 것은?',\n",
        "                 '18. [A]의 서술상 특징으로 가장 적절한 것은?',\n",
        "                 '19. 서사의 흐름을 고려하여 ㉠～㉤에 대해 이해한 내용으로 적절 하지 않은 것은?',\n",
        "                 '20. ⓐ，ⓑ에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '21. <보기>의 관점에서 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '22. (가)와 (나)의 공통점으로 가장 적절한 것은?',\n",
        "                 '23. (나)에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '24. 문맥을 고려하여 ㉠～㉤에 대해 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '25. (나)와 (다)를 비교하여 이해한 내용으로 가장 적절한 것은?',\n",
        "                 '26. [A]와 [B]에 대한 이해로 가장 적절한 것은?',\n",
        "                 '27. 를 바탕으로 (가)～(다)를 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '28. 윗글의 내용에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '29. ⓐ와 ⓑ에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '30. [A]의 ‘달’에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '31. <보기>를 참고하여 ㉠～㉤을 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '32. (가)와 (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '33. (가), (나)의 시어에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '34. <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '35. 위 강연자의 말하기 방식으로 가장 적절한 것은?',\n",
        "                 '36. 다음은 동아리 부장이 강연자에게 보낸 전자 우편이다. 이를 바탕으로 세운 강연자의 계획 중 강연에 반영되지 않은 것은?',\n",
        "                 '37. 다음은 학생이 강연을 들으면서 작성한 메모이다. 이를 바탕 으로 학생의 듣기 과정을 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '38. 대화의 흐름을 고려할 때, ㉠～㉤에 대한 설명으로 적절하지 않은 것은?',\n",
        "                 '39. [A]의 학생 1의 발화에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '40. (가)의 대화 내용이 (나), (다)에 각각 반영된 양상으로 적절 하지 않은 것은?',\n",
        "                 '41. 작문 맥락을 고려할 때 (나), (다)에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '42. <보기>를 점검 기준으로 할 때 ⓐ, ⓑ를 고쳐 쓰기 위한 방안으로 가장 적절한 것은?',\n",
        "                 '43. 다음은 초고를 작성하기 전에 학생이 떠올린 생각이다. ⓐ～ⓔ 중 학생의 초고에 반영되지 않은 것은?',\n",
        "                 '44. 다음은 초고를 읽은 교지 편집부 담당 선생님의 조언이다. 이를 반영하여 [A]를 작성한 내용으로 가장 적절한 것은?',\n",
        "                 '45. <보기>는 학생이 초고를 보완하기 위해 추가로 수집한 자료 이다. 자료의 활용 방안으로 적절하지 않은 것은? [3점]',\n",
        "                 '35. ㉠과 ㉡을 모두 만족하는 용언의 짝으로 적절한 것은?',\n",
        "                 '36. [A]를 바탕으로 의 ⓐ～ⓔ의 밑줄 친 부분을 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '37. <학습 활동>을 수행한 결과로 적절한 것은? [3점]',\n",
        "                 '38. <보기>의 ㉠～㉦에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '39. <보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?',\n",
        "                 '40. 위 화면을 통해 매체의 특성을 이해한 학생의 반응으로 가장 적절한 것은?',\n",
        "                 '41. <보기>를 참고할 때, [A]에 대한 반응으로 적절하지 않은 것은? [3점]',\n",
        "                 '42. 다음은 학생이 과제 수행을 위해 작성한 메모이다. 메모를 반영한 영상 제작 계획으로 적절하지 않은 것은?',\n",
        "                 '43. (가), (나)에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '44. (가)의 언어적 특성을 고려할 때, ㉠～㉤에 대한 설명으로 적절하지 않은 것은?',\n",
        "                 '1. 위 발표에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '2. 다음은 발표를 하기 위해 작성한 메모와 발표 계획이다. 발표 내용에 반영되지 않은 것은?',\n",
        "                 '3. <보기>는 위 발표를 들은 학생들의 반응이다. 발표의 내용을 고려하여 학생의 반응을 이해한 내용으로 가장 적절한 것은?',\n",
        "                 '4. (가)에 나타난 의사소통 방식으로 적절하지 않은 것은?',\n",
        "                 '5. <보기1>은 ‘지도사’가 받은 전자 우편의 내용이고, 는 ‘지도사’가 인터뷰를 위해 준비한 자료이다. ㉠～㉢의 활용 계획 중 (가)에 드러나지 않은 것은? [3점]',\n",
        "                 '6. (가)와 (나)를 고려할 때, 학생이 글을 쓰기 위해 떠올렸을 생각으로 적절하지 않은 것은?',\n",
        "                 '7. 다음을 고려할 때, [A]에 들어갈 내용으로 가장 적절한 것은?',\n",
        "                 '8. ㉠～㉤ 중 (나)에 반영되지 않은 것은?',\n",
        "                 '9. <보기>는 [A]의 초고이다. 를 [A]로 고쳐 쓸 때 반영한 친구의 조언으로 가장 적절한 것은?',\n",
        "                 '10. 다음은 (나)를 읽은 학생이 이를 참고하여 작성한 글의 일부 이다. (나)의 정보를 활용한 방식으로 가장 적절한 것은? [3점]',\n",
        "                 '11. <보기>의 ㉮에 들어갈 말로 적절한 것은?',\n",
        "                 '12. 윗글을 읽고 추론한 내용으로 적절하지 않은 것은?',\n",
        "                 '13. <보기>의 [자료]에서 ㉠에 해당하는 단어만을 있는 대로 고른 것은? [3점]',\n",
        "                 '14. <학습 활동>을 수행한 결과로 적절한 것은?',\n",
        "                 '15. <보기>에 대한 이해로 적절한 것은?',\n",
        "                 '16. [A]의 서술상 특징에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '17. [B]에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '18. 요구 조건 을 중심으로 윗글을 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '19. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '20. (가)와 (나)의 공통적인 내용 전개 방식으로 가장 적절한 것은?',\n",
        "                 '21. (가)의 형식론 에 대한 이해로 가장 적절한 것은?',\n",
        "                 '22. (가)에 등장하는 이론가와 예술가들이 상대의 견해나 작품을 평가할 수 있는 말로 적절하지 않은 것은?',\n",
        "                 '23. 다음은 비평문을 쓰기 위해 미술 전람회에 다녀온 학생이 (가)와 (나)를 읽은 후 작성한 메모의 일부이다. 메모의 내용이 적절하지 않은 것은? [3점]',\n",
        "                 '24. 피카소의 게르니카 에 대해 <보기>의 A는 ㉠의 관점, B는 ㉡의 관점에서 비평한 내용이다. (나)를 바탕으로 A, B를 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '25. 문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?',\n",
        "                 '26. 윗글의 내용과 일치하는 것은?',\n",
        "                 '27. ㉠의 이유로 가장 적절한 것은?',\n",
        "                 '28. 행정규칙 에 관한 설명 중 적절하지 않은 것은?',\n",
        "                 '29. 윗글을 바탕으로 <보기>의 ㉮～㉰에 대해 이해한 내용으로 가장 적절한 것은? [3점]',\n",
        "                 '30. 문맥상 ⓐ～ⓔ와 바꿔 쓰기에 가장 적절한 것은?',\n",
        "                 '31. ㉠에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '32. [A]에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '33. <보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '34. 윗글에서 답을 찾을 수 있는 질문에 해당하지 않는 것은?',\n",
        "                 '35. 윗글을 읽고 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '36. ㉠～㉢에 대한 설명으로 적절한 것은?',\n",
        "                 '37. <보기>는 윗글을 읽은 학생이 ‘가상의 실험 결과’를 보고 추론한 내용이다. [가]에 들어갈 말로 적절하지 않은 것은? [3점]',\n",
        "                 '38. (나)의 시상 전개에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '39. (가)를 참고하여 (나)를 감상한 내용으로 적절하지 않은 것은?',\n",
        "                 '40. (다)를 이해한 내용으로 적절하지 않은 것은?',\n",
        "                 '41. ㉠, ㉡에 대한 설명으로 가장 적절한 것은?',\n",
        "                 '42. ⓐ를 바탕으로 (나), (다)를 이해한 내용으로 적절하지 않은 것은? [3점]',\n",
        "                 '43. (가)에 대한 이해로 가장 적절한 것은?',\n",
        "                 '44. ㉠～㉤에 대한 이해로 적절하지 않은 것은?',\n",
        "                 '45. <보기>를 참고하여 (가), (나)를 감상한 내용으로 적절하지않은 것은? [3점]']\n",
        "\n",
        "print(question_list[-1])\n",
        "# 문제에서 번호 제거\n",
        "# '. ' 기준으로 문제 제거, ex) '37. '를 없앰\n",
        "question_list = [' '.join(tmp.split('. ')[1:]) for tmp in question_list]\n",
        "\n",
        "print('번호 제거 ==>> ', question_list[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "code_folding": [
          0
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "_8lQsRnLi-_9",
        "outputId": "99181456-879a-4f51-f588-2422e2e07ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okt check : ['37', '.', '다음', '은', '3', 'D', '애니메이션', '제작', '을', '위', '한', '계획', '의', '일부', '이다', '.', '윗', '글', '을', '바탕', '으로', '할', '때', '적절하지', '않은', '것', '은', '?', '[', '3', '점', ']']\n"
          ]
        }
      ],
      "source": [
        "## 1) DB에 있는 문장들을 형태소 단위로 쪼개준다\n",
        "tokenizer = 'okt'  # konlpy, no need java, only python\n",
        "\n",
        "# load question list\n",
        "sentence = '37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]'\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt().morphs\n",
        "print('okt check :', tokenizer(sentence))\n",
        "tokenized_corpus = [tokenizer(sentence) for sentence in question_list]  # 형태소 기반 분절\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "code_folding": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "1V2335m0i-_-",
        "outputId": "ffbeae9f-3e25-46a3-d69c-0810c2f5e481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ['윗', '글', '과', '<', '보기', '>', '를', '바탕', '으로', '추론', '한', '내용', '으로', '적절하지', '않은', '것', '은', '?']\n"
          ]
        }
      ],
      "source": [
        "## 2) 모든 문제들의 BM25 벡터를 미리 구한다\n",
        "# BM25 계산\n",
        "bm25_model = BM25Okapi(tokenized_corpus)\n",
        "print('\\n',tokenized_corpus[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "MagjDAzRi-_-",
        "outputId": "b47433d2-da77-4db6-d487-e185ea4c99a6",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]\n",
            "- similar\n",
            "다음은 3D 애니메이션 제작을 위한 계획의 일부이다 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]\n",
            "다음은 학생이 과제 수행을 위해 작성한 메모이다 메모를 반영한 영상 제작 계획으로 적절하지 않은 것은?\n",
            "윗글을 바탕으로 <보기>를 이해한 내용으로 적절하지 않은 것은? [3점]\n",
            "다음은 학생이 강연을 들으면서 작성한 메모이다 이를 바탕 으로 학생의 듣기 과정을 이해한 내용으로 적절하지 않은 것은? [3점]\n",
            "윗글을 바탕으로 베카리아의 입장을 추론한 내용으로 가장 적절한 것은? [3점]\n",
            "윗글을 참고할 때, <보기>의 ㉮에 대한 이해로 적절하지 않은 것은? [3점]\n",
            "윗글을 바탕으로 <보기>의 ㉮～㉰에 대해 이해한 내용으로 가장 적절한 것은? [3점]\n",
            "<보기>의 관점에서 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]\n",
            "<보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]\n",
            "<보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]\n",
            "<보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]\n",
            "<보기>를 참고하여 윗글을 감상한 내용으로 적절하지 않은 것은? [3점]\n",
            "다음을 고려할 때, [A]에 들어갈 내용으로 가장 적절한 것은?\n",
            "<보기>를 참고할 때, [A]에 대한 반응으로 적절하지 않은 것은? [3점]\n",
            "다음은 (나)를 읽은 학생이 이를 참고하여 작성한 글의 일부 이다 (나)의 정보를 활용한 방식으로 가장 적절한 것은? [3점]\n",
            "는 윗글의 주제와 관련한 동서양 학자들의 견해이다 윗글을 읽은 학생이 에 대해 보인 반응으로 적절하지 않은 것은? [3점]\n",
            "다음은 비평문을 쓰기 위해 미술 전람회에 다녀온 학생이 (가)와 (나)를 읽은 후 작성한 메모의 일부이다 메모의 내용이 적절하지 않은 것은? [3점]\n",
            "다음은 윗글을 읽은 학생의 반응이다 이에 대한 설명으로 가장 적절한 것은?\n",
            "다음은 동아리 부장이 강연자에게 보낸 전자 우편이다 이를 바탕으로 세운 강연자의 계획 중 강연에 반영되지 않은 것은?\n",
            "<보기>를 참고하여 ㉠～㉤을 이해한 내용으로 적절하지 않은 것은? [3점]\n"
          ]
        }
      ],
      "source": [
        "query = '37. 다음은 3D 애니메이션 제작을 위한 계획의 일부이다. 윗글을 바탕으로 할 때 적절하지 않은 것은? [3점]'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer, n=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "95I3129Wi-_-",
        "outputId": "9a629ea8-cf60-4a53-daf5-e61a7ec4e32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 39. <보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?\n",
            "- similar\n",
            "<보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?\n",
            "ⓐ～ⓔ는 잘못된 표기를 바르게 고친 것이다 고치는 과정에서 해당 단어에 적용된 용언 활용의 예로 적절하지 않은 것은?\n",
            "<보기>의 [자료]에서 ㉠에 해당하는 단어만을 있는 대로 고른 것은? [3점]\n",
            "<보기>를 점검 기준으로 할 때 ⓐ, ⓑ를 고쳐 쓰기 위한 방안으로 가장 적절한 것은?\n",
            "<보기>를 참고할 때, [A]에 대한 반응으로 적절하지 않은 것은? [3점]\n"
          ]
        }
      ],
      "source": [
        "query = '39. <보기>를 바탕으로 할 때, ㉠～㉢에 해당하는 단어가 사용된 예로 적절한 것은?'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "muM-jCbmi-_-",
        "outputId": "851f8b08-2537-4d9b-8de4-eb6f1cf1da01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 27. ㉠에 대한 이해로 가장 적절한 것은?\n",
            "- similar\n",
            "㉠에 대한 이해로 가장 적절한 것은?\n",
            "㉠에 대한 이해로 적절하지 않은 것은?\n",
            "㉠의 이유로 가장 적절한 것은?\n",
            "㉠, ㉡에 대한 설명으로 가장 적절한 것은?\n",
            "㉠, ㉡에 대한 설명으로 가장 적절한 것은?\n"
          ]
        }
      ],
      "source": [
        "query = '27. ㉠에 대한 이해로 가장 적절한 것은?'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "DjzeM-Lri-_-",
        "outputId": "d0625de1-093c-451b-ed64-755b72baad5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- query : 25. 문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?\n",
            "- similar\n",
            "문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?\n",
            "[A]를 바탕으로 의 ⓐ～ⓔ의 밑줄 친 부분을 이해한 내용으로 적절하지 않은 것은?\n",
            "문맥을 고려할 때 ㉠의 의미를 파악한 내용으로 가장 적절한 것은?\n",
            "대화의 흐름을 고려할 때, ㉠～㉤에 대한 설명으로 적절하지 않은 것은?\n",
            "다음을 고려할 때, [A]에 들어갈 내용으로 가장 적절한 것은?\n"
          ]
        }
      ],
      "source": [
        "query = '25. 문맥을 고려할 때, 밑줄 친 말이 ⓐ～ⓔ의 동음이의어인 것은?'\n",
        "similar_idx, similar_sentences = IR_BM25(query, bm25_model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDCdcpzsi-__"
      },
      "source": [
        "## 문서 분석 완료!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cUSetNZTi-__"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4T7ATsvoC5ez"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tECk1yKL-07X",
        "pXsgP6ZPi-_3",
        "pyPrDUuyi-_5",
        "fQgZ8YGki-_6",
        "bCtGKCoK_mkJ",
        "ToIk_p0qi-_7"
      ],
      "name": "nlp_4_1_document_vector_3_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}